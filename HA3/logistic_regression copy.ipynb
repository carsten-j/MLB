{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c22287f",
   "metadata": {},
   "source": [
    "# Logistic Regression for MNIST Digit Classification\n",
    "\n",
    "This notebook implements logistic regression with L2 regularization for binary classification of MNIST digits 3 and 8. It compares vanilla gradient descent and mini-batch stochastic gradient descent (SGD) optimization methods with different hyperparameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "158bc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rng = np.random.default_rng(3317)\n",
    "plt.style.use(\"ggplot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d18e8cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_3_8():\n",
    "    \"\"\"\n",
    "    Load and preprocess MNIST dataset, filtering for digits 3 and 8.\n",
    "\n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test: Training and test data and labels\n",
    "    \"\"\"\n",
    "    # Load MNIST data\n",
    "    mnist = fetch_openml(\"mnist_784\", version=1)\n",
    "    X, y = mnist.data.astype(float), mnist.target\n",
    "\n",
    "    # Select only digits 3 and 8\n",
    "    mask = (y == \"3\") | (y == \"8\")\n",
    "    X, y = X.loc[mask].values, y.loc[mask].values\n",
    "\n",
    "    # Convert labels to binary (0 for 3, 1 for 8)\n",
    "    y = (y == \"8\").astype(int)\n",
    "\n",
    "    # Normalize pixel values\n",
    "    X = X / 255.0\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f08ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(X, y, num_samples=5):\n",
    "    \"\"\"Visualize sample images from the dataset.\n",
    "\n",
    "    Args:\n",
    "        X: Features\n",
    "        y: Labels (0 for digit 3, 1 for digit 8)\n",
    "        num_samples: Number of samples to display from each class\n",
    "    \"\"\"\n",
    "    # Find indices for each class\n",
    "    indices_3 = np.where(y == 0)[0]\n",
    "    indices_8 = np.where(y == 1)[0]\n",
    "\n",
    "    # Randomly select samples\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    sample_indices_3 = np.random.choice(indices_3, num_samples, replace=False)\n",
    "    sample_indices_8 = np.random.choice(indices_8, num_samples, replace=False)\n",
    "\n",
    "    # Create a figure\n",
    "    _, axes = plt.subplots(2, num_samples, figsize=(15, 6))\n",
    "\n",
    "    # Plot digit 3 samples\n",
    "    for i, idx in enumerate(sample_indices_3):\n",
    "        axes[0, i].imshow(X[idx].reshape(28, 28), cmap=\"gray\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "\n",
    "    # Plot digit 8 samples\n",
    "    for i, idx in enumerate(sample_indices_8):\n",
    "        axes[1, i].imshow(X[idx].reshape(28, 28), cmap=\"gray\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\"./figures/mnist_samples.pdf\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0c001f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(m=784):\n",
    "    \"\"\"\n",
    "    Initialize the model parameters.\n",
    "\n",
    "    Args:\n",
    "        m: Number of features (784 for MNIST)\n",
    "\n",
    "    Returns:\n",
    "        w: Initial weights\n",
    "        b: Initial bias\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    w = np.random.randn(m) * 0.01  # Small random values\n",
    "    b = 0.0\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2686fc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes: \n",
      "  X_train: (11172, 784)\n",
      "  y_train: (11172,)\n",
      "  X_test: (2794, 784)\n",
      "  y_test: (2794,)\n",
      "\n",
      "Class distribution:\n",
      "  Training set: 5713 instances of digit 3, 5459 instances of digit 8\n",
      "  Test set: 1428 instances of digit 3, 1366 instances of digit 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 14 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and visualize dataset samples\n",
    "X_train, X_test, y_train, y_test = load_mnist_3_8()\n",
    "print(\n",
    "    f\"Dataset shapes: \\n  X_train: {X_train.shape}\\n  y_train: {y_train.shape}\\n  X_test: {X_test.shape}\\n  y_test: {y_test.shape}\"\n",
    ")\n",
    "\n",
    "# Count class distribution in training and test sets\n",
    "print(\n",
    "    f\"\\nClass distribution:\\n  Training set: {np.sum(y_train == 0)} instances of digit 3, {np.sum(y_train == 1)} instances of digit 8\"\n",
    ")\n",
    "print(\n",
    "    f\"  Test set: {np.sum(y_test == 0)} instances of digit 3, {np.sum(y_test == 1)} instances of digit 8\"\n",
    ")\n",
    "\n",
    "# Show sample images\n",
    "visualize_samples(X_train, y_train, num_samples=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "56788287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Numerically stable sigmoid activation function.\n",
    "\n",
    "    Args:\n",
    "        z: Input values\n",
    "\n",
    "    Returns:\n",
    "        Sigmoid values\n",
    "    \"\"\"\n",
    "    # Clip to avoid overflow\n",
    "    z = np.clip(z, -500, 500)\n",
    "\n",
    "    # Separate computation for positive and negative values for numerical stability\n",
    "    mask = z >= 0\n",
    "    result = np.zeros_like(z, dtype=float)\n",
    "\n",
    "    # For z >= 0: 1 / (1 + exp(-z))\n",
    "    result[mask] = 1.0 / (1.0 + np.exp(-z[mask]))\n",
    "\n",
    "    # For z < 0: exp(z) / (1 + exp(z)) to avoid large exp(-z)\n",
    "    exp_z = np.exp(z[~mask])\n",
    "    result[~mask] = exp_z / (1.0 + exp_z)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0f7d9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    \"\"\"\n",
    "    Make predictions using the logistic regression model.\n",
    "\n",
    "    Args:\n",
    "        X: Features\n",
    "        w: Weights\n",
    "        b: Bias\n",
    "\n",
    "    Returns:\n",
    "        Predicted probabilities\n",
    "    \"\"\"\n",
    "    z = np.dot(X, w) + b\n",
    "    return sigmoid(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X, y, w, b, mu):\n",
    "    \"\"\"\n",
    "    Compute the cross-entropy loss with L2 regularization.\n",
    "\n",
    "    Args:\n",
    "        X: Features\n",
    "        y: True labels\n",
    "        w: Weights\n",
    "        b: Bias\n",
    "        mu: Regularization parameter\n",
    "\n",
    "    Returns:\n",
    "        Total loss value\n",
    "    \"\"\"\n",
    "    p = predict(X, w, b)\n",
    "\n",
    "    # Avoid log(0) errors\n",
    "    p = np.clip(p, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    # Cross-entropy loss\n",
    "    cross_entropy = -np.mean(y * np.log(p) + (1 - y) * np.log(1 - p))\n",
    "\n",
    "    # L2 regularization\n",
    "    regularization = (mu / 2) * (np.sum(w**2) + b**2)\n",
    "\n",
    "    return cross_entropy + regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f5861c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(X, y, w, b, mu):\n",
    "    \"\"\"\n",
    "    Compute the gradients of the loss function with respect to parameters.\n",
    "\n",
    "    Args:\n",
    "        X: Features\n",
    "        y: True labels\n",
    "        w: Weights\n",
    "        b: Bias\n",
    "        mu: Regularization parameter\n",
    "\n",
    "    Returns:\n",
    "        dw: Gradient with respect to w\n",
    "        db: Gradient with respect to b\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    p = predict(X, w, b)\n",
    "\n",
    "    # Gradient for w\n",
    "    dw = np.dot(X.T, (p - y)) / n + mu * w\n",
    "\n",
    "    # Gradient for b\n",
    "    db = np.sum(p - y) / n + mu * b\n",
    "\n",
    "    return dw, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "68918332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_misclassifications(X, y, w, b, num_examples=5):\n",
    "    \"\"\"\n",
    "    Visualize examples that were misclassified by the model.\n",
    "\n",
    "    Args:\n",
    "        X: Features\n",
    "        y: True labels\n",
    "        w: Trained weights\n",
    "        b: Trained bias\n",
    "        num_examples: Number of misclassified examples to show\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    p = predict(X, w, b)\n",
    "    y_pred = (p >= 0.5).astype(int)\n",
    "\n",
    "    # Find misclassified examples\n",
    "    misclassified = np.where(y_pred != y)[0]\n",
    "\n",
    "    if len(misclassified) == 0:\n",
    "        print(\"No misclassified examples found!\")\n",
    "        return\n",
    "\n",
    "    # Select a subset of misclassified examples\n",
    "    indices = misclassified[: min(num_examples, len(misclassified))]\n",
    "\n",
    "    # Plot the examples\n",
    "    fig, axes = plt.subplots(1, len(indices), figsize=(15, 3))\n",
    "    if len(indices) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        img = X[idx].reshape(28, 28)\n",
    "        axes[i].imshow(img, cmap=\"gray\")\n",
    "        axes[i].set_title(\n",
    "            f\"True: {3 if y[idx] == 0 else 8}\\nPred: {3 if y_pred[idx] == 0 else 8}\"\n",
    "        )\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0a0e6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    learning_rate,\n",
    "    num_epochs,\n",
    "    mu,\n",
    "    method=\"vanilla\",\n",
    "    batch_size=10,\n",
    "    diminishing_lr=False,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model using either vanilla gradient descent or mini-batch SGD.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training labels\n",
    "        learning_rate: Initial learning rate for gradient updates\n",
    "        num_epochs: Number of training epochs\n",
    "        mu: Regularization parameter\n",
    "        method: 'vanilla' for vanilla gradient descent or 'sgd' for mini-batch SGD\n",
    "        batch_size: Size of mini-batches (only used if method='sgd')\n",
    "        diminishing_lr: If True, use diminishing learning rate γ = learning_rate/t for SGD\n",
    "        verbose: Whether to print progress\n",
    "\n",
    "    Returns:\n",
    "        w: Trained weights\n",
    "        b: Trained bias\n",
    "        loss_history: History of loss values during training\n",
    "    \"\"\"\n",
    "    m = X_train.shape[1]  # Number of features (784 for MNIST)\n",
    "    n = X_train.shape[0]  # Number of training examples\n",
    "\n",
    "    # Initialize parameters\n",
    "    w, b = initialize_parameters(m)\n",
    "\n",
    "    # Initialize loss history\n",
    "    loss_history = []\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Calculate current learning rate for SGD if using diminishing schedule\n",
    "        current_lr = learning_rate\n",
    "        if method == \"sgd\" and diminishing_lr:\n",
    "            # t starts from 1, so epoch + 1\n",
    "            current_lr = learning_rate / (epoch + 1)\n",
    "            if verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch + 1}: Current learning rate = {current_lr:.6f}\")\n",
    "\n",
    "        if method == \"vanilla\":\n",
    "            # Vanilla gradient descent: compute gradients on entire dataset\n",
    "            dw, db = compute_gradients(X_train, y_train, w, b, mu)\n",
    "\n",
    "            # Update parameters\n",
    "            w = w - learning_rate * dw\n",
    "            b = b - learning_rate * db\n",
    "\n",
    "        elif method == \"sgd\":\n",
    "            # Mini-batch SGD: process data in batches\n",
    "\n",
    "            # Shuffle data\n",
    "            indices = np.random.permutation(n)\n",
    "            X_shuffled = X_train[indices]\n",
    "            y_shuffled = y_train[indices]\n",
    "\n",
    "            # Process each mini-batch\n",
    "            for i in range(0, n, batch_size):\n",
    "                X_batch = X_shuffled[i : i + batch_size]\n",
    "                y_batch = y_shuffled[i : i + batch_size]\n",
    "\n",
    "                # Compute gradients on mini-batch\n",
    "                dw, db = compute_gradients(X_batch, y_batch, w, b, mu)\n",
    "\n",
    "                # Update parameters with current learning rate\n",
    "                w = w - current_lr * dw\n",
    "                b = b - current_lr * db\n",
    "        else:\n",
    "            raise ValueError(\"Method must be either 'vanilla' or 'sgd'\")\n",
    "\n",
    "        # Compute and store loss for the epoch\n",
    "        loss = compute_loss(X_train, y_train, w, b, mu)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        # Print loss every 10 epochs as required\n",
    "        if verbose and (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return w, b, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fdcc1925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        X: Features\n",
    "        y: True labels\n",
    "        w: Weights\n",
    "        b: Bias\n",
    "\n",
    "    Returns:\n",
    "        accuracy: Classification accuracy\n",
    "    \"\"\"\n",
    "    p = predict(X, w, b)\n",
    "    y_pred = (p >= 0.5).astype(int)\n",
    "    accuracy = np.mean(y_pred == y)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "998e35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_mnist_3_8(\n",
    "    learning_rate,\n",
    "    mu,\n",
    "    num_epochs=100,\n",
    "    method=\"vanilla\",\n",
    "    batch_size=10,\n",
    "    diminishing_lr=False,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model to classify MNIST digits 3 and 8.\n",
    "\n",
    "    Args:\n",
    "        learning_rate: Initial learning rate for gradient descent\n",
    "        mu: Regularization parameter\n",
    "        num_epochs: Number of training epochs\n",
    "        method: 'vanilla' for vanilla gradient descent or 'sgd' for mini-batch SGD\n",
    "        batch_size: Size of mini-batches (only used if method='sgd')\n",
    "        diminishing_lr: If True, use diminishing learning rate γ = learning_rate/t (only used if method='sgd')\n",
    "\n",
    "    Returns:\n",
    "        w: Trained weights\n",
    "        b: Trained bias\n",
    "        loss_history: Training loss after each epoch\n",
    "        test_accuracy: Accuracy on the test set\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    X_train, X_test, y_train, y_test = load_mnist_3_8()\n",
    "\n",
    "    lr_schedule = \"diminishing\" if diminishing_lr and method == \"sgd\" else \"constant\"\n",
    "    print(\n",
    "        f\"Training with method={method}, learning_rate={learning_rate} ({lr_schedule}), mu={mu}\"\n",
    "    )\n",
    "    print(f\"Dataset shape: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "\n",
    "    # Train the model\n",
    "    w, b, loss_history = train_model(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        learning_rate,\n",
    "        num_epochs,\n",
    "        mu,\n",
    "        method,\n",
    "        batch_size,\n",
    "        diminishing_lr,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_accuracy = evaluate(X_test, y_test, w, b)\n",
    "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Plot loss history\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), loss_history)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\n",
    "        f\"Training Loss (method={method}, lr={learning_rate} ({lr_schedule}), mu={mu})\"\n",
    "    )\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\n",
    "        f\"./figures/{method}_{learning_rate}_{lr_schedule}.pdf\",\n",
    "        dpi=600,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    return w, b, loss_history, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5218fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(results_dict, filename=\"learning_curves\"):\n",
    "    \"\"\"\n",
    "    Plot learning curves for multiple models side by side.\n",
    "\n",
    "    Args:\n",
    "        results_dict: Dictionary with model names as keys and (loss_history, params) as values\n",
    "                     where params is a dictionary of hyperparameters\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for model_name, (loss_history, params) in results_dict.items():\n",
    "        epochs = range(1, len(loss_history) + 1)\n",
    "        plt.plot(epochs, loss_history, label=model_name)\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Comparison\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"./figures/{filename}.pdf\", dpi=600, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e221fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_methods_and_hyperparameters(\n",
    "    methods=[\"vanilla\"],\n",
    "    learning_rates=[0.001],\n",
    "    batch_sizes=[10],\n",
    "    mu=1.0,\n",
    "    epochs=1000,\n",
    "    diminishing_lr=False,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare vanilla gradient descent and mini-batch SGD with different hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        methods: List of optimization methods to compare ('vanilla' or 'sgd')\n",
    "        learning_rates: List of learning rates to test\n",
    "        batch_sizes: List of batch sizes to test (only applicable for 'sgd')\n",
    "        mu: Regularization parameter\n",
    "        epochs: Number of training epochs\n",
    "        diminishing_lr: Whether to use diminishing learning rate for SGD\n",
    "        verbose: Whether to print progress during training\n",
    "\n",
    "    Returns:\n",
    "        results: List of dictionaries with results for each configuration\n",
    "        models_info: Dictionary with model names as keys and (weights, bias, loss_history) as values\n",
    "        best_w: Weights of the best performing model\n",
    "        best_b: Bias of the best performing model\n",
    "        comparison_data: Data for comparison plots\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    models_info = {}\n",
    "    best_accuracy = 0\n",
    "    best_model_name = \"\"\n",
    "    best_w, best_b = None, None\n",
    "\n",
    "    for method in methods:\n",
    "        for lr in learning_rates:\n",
    "            for batch_size in batch_sizes:\n",
    "                # Only consider batch sizes for SGD\n",
    "                if method == \"vanilla\" and batch_size != batch_sizes[0]:\n",
    "                    continue\n",
    "\n",
    "                model_name = f\"{method}_lr_{lr}\"\n",
    "                if method == \"sgd\":\n",
    "                    model_name += f\"_bs_{batch_size}\"\n",
    "                if diminishing_lr and method == \"sgd\":\n",
    "                    model_name += \"_dim\"\n",
    "\n",
    "                print(f\"\\nTraining with {model_name}, mu={mu}\")\n",
    "\n",
    "                w, b, loss_history, test_accuracy = logistic_regression_mnist_3_8(\n",
    "                    lr,\n",
    "                    mu,\n",
    "                    num_epochs=epochs,\n",
    "                    method=method,\n",
    "                    batch_size=batch_size,\n",
    "                    diminishing_lr=diminishing_lr,\n",
    "                    verbose=verbose,\n",
    "                )\n",
    "\n",
    "                # Store detailed results\n",
    "                result = {\n",
    "                    \"model_name\": model_name,\n",
    "                    \"method\": method,\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"batch_size\": batch_size if method == \"sgd\" else \"N/A\",\n",
    "                    \"diminishing_lr\": diminishing_lr if method == \"sgd\" else \"N/A\",\n",
    "                    \"mu\": mu,\n",
    "                    \"num_epochs\": epochs,\n",
    "                    \"final_loss\": loss_history[-1],\n",
    "                    \"test_accuracy\": test_accuracy,\n",
    "                }\n",
    "\n",
    "                results.append(result)\n",
    "\n",
    "                # Store model parameters and loss history\n",
    "                models_info[model_name] = (w, b, loss_history)\n",
    "\n",
    "                # Track best model\n",
    "                if test_accuracy > best_accuracy:\n",
    "                    best_accuracy = test_accuracy\n",
    "                    best_model_name = model_name\n",
    "                    best_w, best_b = w, b\n",
    "\n",
    "    # Print results table\n",
    "    print(\"\\nResults Summary:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(\n",
    "        f\"{'Model':<20}{'Method':<10}{'Learning Rate':<15}{'Batch Size':<15}{'Final Loss':<15}{'Test Accuracy':<15}\"\n",
    "    )\n",
    "    print(\"-\" * 100)\n",
    "    for result in results:\n",
    "        print(\n",
    "            f\"{result['model_name']:<20}{result['method']:<10}{result['learning_rate']:<15}{result['batch_size']:<15}\"\n",
    "            f\"{result['final_loss']:<15.4f}{result['test_accuracy']:<15.4f}\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\nBest model: {best_model_name} with test accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    # Prepare data for comparison plots\n",
    "    comparison_data = {}\n",
    "    for name, (_, _, loss_hist) in models_info.items():\n",
    "        comparison_data[name] = (loss_hist, {})\n",
    "\n",
    "    return results, models_info, best_w, best_b, comparison_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d0af7769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Training with mini-batch SGD (diminising learning rate):\n",
      "Training with method=sgd, learning_rate=1 (diminishing), mu=1\n",
      "Dataset shape: X_train: (11172, 784), y_train: (11172,)\n",
      "Epoch 10: Current learning rate = 0.100000\n",
      "Epoch 10/50, Loss: 0.8868\n",
      "Epoch 20: Current learning rate = 0.050000\n",
      "Epoch 20/50, Loss: 0.5285\n",
      "Epoch 30: Current learning rate = 0.033333\n",
      "Epoch 30/50, Loss: 0.5097\n",
      "Epoch 40: Current learning rate = 0.025000\n",
      "Epoch 40/50, Loss: 0.5471\n",
      "Epoch 50: Current learning rate = 0.020000\n",
      "Epoch 50/50, Loss: 0.5106\n",
      "Test accuracy: 0.9080\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Question 3: Single model experiments\n",
    "    print(\"\\n=== Question 3: Single Model Experiments ===\")\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    mu = 1  # Regularization parameter\n",
    "\n",
    "    print(\"\\n1. Training with vanilla gradient descent:\")\n",
    "    w_vanilla, b_vanilla, loss_vanilla, test_acc_vanilla = (\n",
    "        logistic_regression_mnist_3_8(\n",
    "            learning_rate, mu, num_epochs=1200, method=\"vanilla\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Single run with mini-batch SGD (constant learning rate)\n",
    "    print(\"\\n2. Training with mini-batch SGD (constant learning rate):\")\n",
    "    w_sgd, b_sgd, loss_sgd, test_acc_sgd = logistic_regression_mnist_3_8(\n",
    "        learning_rate, mu, num_epochs=100, method=\"sgd\", batch_size=10\n",
    "    )\n",
    "\n",
    "    # Comparison 1: Learning rate impact on SGD\n",
    "    # print(\"\\nComparing different learning rates for Gradient Descend:\")\n",
    "    # results1, models1, best_w1, best_b1, comp_data1 = (\n",
    "    #     compare_methods_and_hyperparameters(\n",
    "    #         methods=[\"vanilla\"],\n",
    "    #         learning_rates=[0.0001, 0.001, 0.01],\n",
    "    #         batch_sizes=[10],\n",
    "    #         epochs=1200,\n",
    "    #         diminishing_lr=False,\n",
    "    #         verbose=False,\n",
    "    #     )\n",
    "    # )\n",
    "    # plot_learning_curves(comp_data1, \"gc_learning_rates\")\n",
    "\n",
    "    # print(\"\\nComparing different learning rates for SGD:\")\n",
    "    # results1, models1, best_w1, best_b1, comp_data1 = (\n",
    "    #     compare_methods_and_hyperparameters(\n",
    "    #         methods=[\"sgd\"],\n",
    "    #         learning_rates=[0.0001, 0.001, 0.01],\n",
    "    #         batch_sizes=[10],\n",
    "    #         epochs=50,\n",
    "    #         diminishing_lr=False,\n",
    "    #         verbose=False,\n",
    "    #     )\n",
    "    # )\n",
    "    # plot_learning_curves(comp_data1, \"sgd_learning_rates\")\n",
    "\n",
    "    # print(\"\\nComparing different batch sizes for SGD:\")\n",
    "    # results1, models1, best_w1, best_b1, comp_data1 = (\n",
    "    #     compare_methods_and_hyperparameters(\n",
    "    #         methods=[\"sgd\"],\n",
    "    #         learning_rates=[0.001],\n",
    "    #         batch_sizes=[1, 10, 100],\n",
    "    #         epochs=50,\n",
    "    #         diminishing_lr=False,\n",
    "    #         verbose=False,\n",
    "    #     )\n",
    "    # )\n",
    "    # plot_learning_curves(comp_data1, \"sgd_batch_sizes\")\n",
    "\n",
    "    # num_epochs = 50\n",
    "    # # Single run with mini-batch SGD (constant learning rate)\n",
    "    # print(\"\\n2. Training with mini-batch SGD (diminising learning rate):\")\n",
    "    # w_sgd, b_sgd, loss_sgd, test_acc_sgd = logistic_regression_mnist_3_8(\n",
    "    #     learning_rate=1,\n",
    "    #     mu=1,\n",
    "    #     num_epochs=num_epochs,\n",
    "    #     method=\"sgd\",\n",
    "    #     batch_size=10,\n",
    "    #     diminishing_lr=True,\n",
    "    # )\n",
    "\n",
    "    # # Single run with mini-batch SGD (diminishing learning rate)\n",
    "    # print(\"\\n3. Training with mini-batch SGD (diminishing learning rate):\")\n",
    "    # w_sgd_dim, b_sgd_dim, loss_sgd_dim, test_acc_sgd_dim = (\n",
    "    #     logistic_regression_mnist_3_8(\n",
    "    #         learning_rate,\n",
    "    #         mu,\n",
    "    #         num_epochs=num_epochs,\n",
    "    #         method=\"sgd\",\n",
    "    #         batch_size=10,\n",
    "    #         diminishing_lr=True,\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    # # Compare learning curves\n",
    "    # single_models = {\n",
    "    #     \"Vanilla GD\": (loss_vanilla, {}),\n",
    "    #     \"Mini-batch SGD (constant lr)\": (loss_sgd, {}),\n",
    "    #     \"Mini-batch SGD (diminishing lr)\": (loss_sgd_dim, {}),\n",
    "    # }\n",
    "    # plot_learning_curves(single_models)\n",
    "\n",
    "    # # Visualize decision boundaries\n",
    "    # X_train, X_test, y_train, y_test = load_mnist_3_8()\n",
    "    # print(\"\\nVisualizing decision boundary of the best model:\")\n",
    "    # best_model_idx = np.argmax([test_acc_vanilla, test_acc_sgd, test_acc_sgd_dim])\n",
    "    # best_w, best_b = (\n",
    "    #     [w_vanilla, w_sgd, w_sgd_dim][best_model_idx],\n",
    "    #     [b_vanilla, b_sgd, b_sgd_dim][best_model_idx],\n",
    "    # )\n",
    "    # visualize_decision_boundary(X_test, y_test, best_w, best_b)\n",
    "\n",
    "    # # Visualize misclassifications\n",
    "    # print(\"\\nVisualizing misclassifications:\")\n",
    "    # visualize_misclassifications(X_test, y_test, best_w, best_b, num_examples=5)\n",
    "\n",
    "    # # PART 2: Hyperparameter comparison\n",
    "    # print(\"\\n=== PART 2: Hyperparameter Comparison ===\")\n",
    "\n",
    "    # # Comparison 1: Learning rate impact on SGD\n",
    "    # print(\"\\nComparing different learning rates for SGD:\")\n",
    "    # results1, models1, best_w1, best_b1, comp_data1 = (\n",
    "    #     compare_methods_and_hyperparameters(\n",
    "    #         methods=[\"sgd\"],\n",
    "    #         learning_rates=[0.0001, 0.001, 0.01],\n",
    "    #         batch_sizes=[10],\n",
    "    #         epochs=50,\n",
    "    #         diminishing_lr=False,\n",
    "    #         verbose=False,\n",
    "    #     )\n",
    "    # )\n",
    "    # plot_learning_curves(comp_data1)\n",
    "\n",
    "    # # Comparison 2: Batch size impact on SGD\n",
    "    # print(\"\\nComparing different batch sizes for SGD:\")\n",
    "    # results2, models2, best_w2, best_b2, comp_data2 = (\n",
    "    #     compare_methods_and_hyperparameters(\n",
    "    #         methods=[\"sgd\"],\n",
    "    #         learning_rates=[0.001],\n",
    "    #         batch_sizes=[1, 10, 100],\n",
    "    #         epochs=50,\n",
    "    #         diminishing_lr=False,\n",
    "    #         verbose=False,\n",
    "    #     )\n",
    "    # )\n",
    "    # plot_learning_curves(comp_data2)\n",
    "\n",
    "    # # Comparison 3: Vanilla GD vs. SGD with constant vs. diminishing learning rate\n",
    "    # print(\"\\nComparing Vanilla GD vs. SGD (constant lr) vs. SGD (diminishing lr):\")\n",
    "    # results3, models3, best_w3, best_b3, comp_data3 = (\n",
    "    #     compare_methods_and_hyperparameters(\n",
    "    #         methods=[\"vanilla\", \"sgd\", \"sgd\"],\n",
    "    #         learning_rates=[0.001, 0.001, 0.001],\n",
    "    #         batch_sizes=[10],  # Will only be used for SGD\n",
    "    #         epochs=50,\n",
    "    #         diminishing_lr=[False, False, True],  # Only apply to the second SGD\n",
    "    #         verbose=False,\n",
    "    #     )\n",
    "    # )\n",
    "    # plot_learning_curves(comp_data3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6124e4",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we implemented logistic regression with L2 regularization for binary classification of MNIST digits 3 and 8. We compared two optimization methods:\n",
    "\n",
    "1. **Vanilla Gradient Descent**: Updates parameters using the entire dataset at each iteration.\n",
    "2. **Mini-batch Stochastic Gradient Descent (SGD)**: Updates parameters using small batches of data, with either constant or diminishing learning rates.\n",
    "\n",
    "Our experiments demonstrate several key findings:\n",
    "\n",
    "- SGD typically converges faster than vanilla gradient descent due to more frequent parameter updates.\n",
    "- The choice of learning rate significantly impacts the convergence speed and final performance.\n",
    "- Batch size affects both training stability and convergence speed:\n",
    "  - Smaller batches lead to noisier updates but can help escape local minima.\n",
    "  - Larger batches provide more stable gradients but can slow down convergence.\n",
    "- Diminishing learning rates can help SGD achieve better convergence by reducing the update step size over time.\n",
    "\n",
    "Future improvements could include:\n",
    "- Implementing more advanced optimization methods like Adam or RMSProp.\n",
    "- Adding early stopping to prevent overfitting.\n",
    "- Exploring different regularization techniques.\n",
    "- Extending the model to multi-class classification for all MNIST digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cddca7",
   "metadata": {},
   "source": [
    "---\n",
    "* __Author__: Carsten Jørgensen \n",
    "* __Date__: May 2025  \n",
    "* __Course__: Machine Learning B  \n",
    "* __Assignment__: Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a394b5",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7566a19",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a469f4de",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
